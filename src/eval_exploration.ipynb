{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "import itertools\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data = pandas.read_pickle(\"../aggregate_data.pkl\")\n",
    "ground_truth_data = pandas.read_pickle(\"../ground_truth_data.pkl\")\n",
    "inferred_data = pandas.read_pickle(\"../inferred_data.pkl\")\n",
    "aggregate_data.columns\n",
    "#inferred_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    ".groupby([\"method_name\", \"system_name\", \"num_train_trajectories\"])\\\n",
    ".agg({\"relerr_l2\" : \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_name = \"spring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(20)\n",
    "\n",
    "df = pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    ".query(\"system_name == 'wave'\")\\\n",
    ".groupby([\"system_name\", \"method_name\", \"num_train_trajectories\", \"timestep_number\"])\\\n",
    ".agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "df.loc[df[\"method_name\"] == \"mlp\"]\\\n",
    ".pivot(index=\"timestep_number\", columns=[\"method_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    ".plot(ax=ax[0,0], logy=True)\n",
    "\n",
    "df.loc[df[\"method_name\"] == \"hnn\"]\\\n",
    ".pivot(index=\"timestep_number\", columns=[\"method_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    ".plot(ax=ax[1,0], logy=True)\n",
    "\n",
    "df.loc[df[\"method_name\"] == \"srnn\"]\\\n",
    ".pivot(index=\"timestep_number\", columns=[\"method_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    ".plot(ax=ax[0,1], logy=True)\n",
    "\n",
    "df.loc[df[\"method_name\"] == \"knn-regressor\"]\\\n",
    ".pivot(index=\"timestep_number\", columns=[\"method_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    ".plot(ax=ax[1,1], logy=True)\n",
    "\n",
    "plt.suptitle(\"Spring\")\n",
    "\n",
    "def style_update(ax):\n",
    "    ax.grid()\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_xlabel(\"Timestep number\")\n",
    "    ax.set_ylabel(\"Relative Error (mean over trajectories)\")\n",
    "    \n",
    "\n",
    "[style_update(ax) for ax in itertools.chain(*ax)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_system_performance(system_name):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.suptitle(system_name)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    df = pandas\\\n",
    "    .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "    .query(\"system_name == '{}'\".format(system_name))\\\n",
    "    .groupby([\"method_name\", \"system_name\", \"num_train_trajectories\"])\\\n",
    "    .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    df\\\n",
    "    .pivot(index=\"method_name\", columns=[\"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    "    .plot(ax=ax[0], kind=\"bar\", logy=True)\n",
    "\n",
    "    df\\\n",
    "    .pivot(index=\"num_train_trajectories\", columns=[\"method_name\"], values=\"mean_relerr_l2\")\\\n",
    "    .plot(ax=ax[1], kind=\"bar\", logy=True)\n",
    "\n",
    "    def style_update(ax):\n",
    "        ax.grid()\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        ax.legend(loc=\"upper center\")\n",
    "        ax.set_ylabel(\"Relative Error (mean over trajectories, timesteps)\")\n",
    "\n",
    "    [style_update(ax_) for ax_ in ax]\n",
    "    plt.show()\n",
    "\n",
    "plot_system_performance(\"spring\")\n",
    "plot_system_performance(\"wave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\n",
    "df = pandas.merge(df, ground_truth_data, on=[\"experiment_name\", \"trajectory_number\", \"timestep_number\"])\n",
    "run_df = df.loc[(df[\"system_name\"] == \"wave\") &\n",
    "                (df[\"method_name\"] == \"srnn\") & \n",
    "                (df[\"network_depth\"] == 3) & \n",
    "                (df[\"network_hidden_dim\"] == 500) & \n",
    "                (df[\"num_train_trajectories\"] == 1000)]\n",
    "run_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = run_df.loc[(run_df[\"trajectory_number\"] == 0)][[\"inferred_data\", \"ground_truth_data\"]]\n",
    "inferred_data_ = np.stack([entry[0] for entry in single_run.values])\n",
    "ground_truth_data_ = np.stack([entry[1] for entry in single_run.values])\n",
    "def plot_t(t):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(inferred_data_[t, ...], \"*\")\n",
    "    plt.plot(ground_truth_data_[t, ...], \".-\")\n",
    "    plt.plot()\n",
    "\n",
    "widgets.interact(plot_t, t=widgets.IntSlider(value=0, min=0, max=29))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_system_performance(system_name):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.suptitle(system_name)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    df = pandas\\\n",
    "    .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "    .groupby([\"method_name\", \"system_name\"])\\\n",
    "    .agg({\"inference_time\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    df\\\n",
    "    .pivot(index=\"method_name\", columns=[\"system_name\"], values=\"mean_inference_time\")\\\n",
    "    .plot(ax=ax, kind=\"bar\", logy=True)\n",
    "        \n",
    "\n",
    "    def style_update(ax):\n",
    "        ax.grid()\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        ax.legend(loc=\"upper center\")\n",
    "        ax.set_ylabel(\"Relative Error (mean over trajectories, timesteps)\")\n",
    "\n",
    "    style_update(ax)\n",
    "    plt.show()\n",
    "plot_system_performance(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
