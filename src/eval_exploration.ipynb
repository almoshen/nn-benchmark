{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "import itertools\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/home/karl/benchmark-project/learn-physics-spring/\"\n",
    "# data_dir = \"/home/karl/benchmark-project/learn-integration-spring/\"\n",
    "data_dir = \"/home/karl/benchmark-project/wave-architecture-test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data = pandas.read_pickle(os.path.join(data_dir, \"aggregate_data.pkl\"))\n",
    "ground_truth_data = pandas.read_pickle(os.path.join(data_dir, \"ground_truth_data.pkl\"))\n",
    "inferred_data = pandas.read_pickle(os.path.join(data_dir, \"inferred_data.pkl\"))\n",
    "aggregate_data.columns\n",
    "#inferred_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_rows', 216)\n",
    "pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    ".groupby([\"method_name\", \"system_name\", \"num_train_trajectories\", \"integrator_timestep_size\"])\\\n",
    ".agg({\"relerr_l2\" : \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_plots(system_name, methods=None, integrator=None, out_of_distribution=None):\n",
    "    fig, ax = plt.subplots(3, 2)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(30)\n",
    "    \n",
    "    if not methods:\n",
    "        methods = [\"hnn\", \"mlp\", \"knn-regressor\", \"knn-predictor\", \"integrator_baseline\"]\n",
    "    \n",
    "    query_string = \"system_name == '{}'\".format(system_name)\n",
    "    if integrator:\n",
    "        query_string += \" and integrator_name == '{}'\".format(integrator)\n",
    "    if out_of_distribution is not None:\n",
    "        query_string += \" and {} experiment_name.str.contains('outdist')\".format(\"\" if out_of_distribution else \"not\")\n",
    "\n",
    "    if \"mlp\" in methods or \"hnn\" in methods:\n",
    "        df = pandas\\\n",
    "        .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "        .query(query_string)\\\n",
    "        .groupby([\"method_name\", \"integrator_name\", \"num_train_trajectories\", \"network_depth\", \"network_hidden_dim\", \"timestep_number\"])\\\n",
    "        .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    if \"mlp\" in methods:\n",
    "        df.loc[df[\"method_name\"] == \"mlp\"]\\\n",
    "        .pivot(index=\"timestep_number\", columns=[\"method_name\", \"integrator_name\", \"network_depth\", \"network_hidden_dim\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    "        .plot(ax=ax[0,0], logy=True)\n",
    "\n",
    "    if \"hnn\" in methods:\n",
    "        df.loc[df[\"method_name\"] == \"hnn\"]\\\n",
    "        .pivot(index=\"timestep_number\", columns=[\"method_name\", \"integrator_name\", \"network_depth\", \"network_hidden_dim\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    "        .plot(ax=ax[0,1], logy=True)\n",
    "\n",
    "    if \"knn-regressor\" in methods or \"knn-predictor\" in methods:\n",
    "        df = pandas\\\n",
    "        .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "        .query(\"system_name == '{}'\".format(system_name))\\\n",
    "        .groupby([\"method_name\", \"integrator_name\", \"num_train_trajectories\", \"timestep_number\"])\\\n",
    "        .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    if \"knn-regressor\" in methods:\n",
    "        df.loc[df[\"method_name\"] == \"knn-regressor\"]\\\n",
    "        .pivot(index=\"timestep_number\", columns=[\"method_name\", \"integrator_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    "        .plot(ax=ax[1,0], logy=True)\n",
    "\n",
    "    if \"knn-predictor\" in methods:\n",
    "        df.loc[df[\"method_name\"] == \"knn-predictor\"]\\\n",
    "        .pivot(index=\"timestep_number\", columns=[\"method_name\", \"num_train_trajectories\"], values=\"mean_relerr_l2\")\\\n",
    "        .plot(ax=ax[1,1], logy=True)\n",
    "\n",
    "    if \"integrator-baseline\" in methods:\n",
    "        df = pandas\\\n",
    "        .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "        .query(\"system_name == '{}'\".format(system_name))\\\n",
    "        .groupby([\"method_name\", \"integrator_name\", \"timestep_number\"])\\\n",
    "        .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "        df.loc[df[\"method_name\"] == \"integrator-baseline\"]\\\n",
    "        .pivot(index=\"timestep_number\", columns=[\"method_name\", \"integrator_name\"], values=\"mean_relerr_l2\")\\\n",
    "        .plot(ax=ax[2,0], logy=True)\n",
    "\n",
    "    def style_update(ax):\n",
    "        max_val = df[\"mean_relerr_l2\"].max()\n",
    "        ax.set(ylim=(1e-6, 1e1))\n",
    "        ax.grid()\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        ax.set_xlabel(\"Timestep number\")\n",
    "        ax.set_ylabel(\"Relative Error (mean over trajectories)\")\n",
    "\n",
    "\n",
    "    [style_update(ax) for ax in itertools.chain(*ax)]\n",
    "    [ax_.set_title(title) for ax_, title in zip(itertools.chain(*ax), itertools.chain([\"MLP\", \"HNN\"], [\"KNN-REGRESSOR\", \"KNN-PREDICTOR\"], [\"INTEGRATOR-BASELINE\"]))]\n",
    "    ax[2,1].set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    # plt.show()\n",
    "    # plt.savefig(\"error_timestep.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_system_plots(\"wave\", methods=[\"hnn\", \"integrator-baseline\"], integrator=None, out_of_distribution=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    ".query(\"system_name == '{}'\".format(\"spring\"))\\\n",
    ".groupby([\"method_name\", \"integrator_name\"])\\\n",
    ".agg({\"inference_time\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_system_performance(system_name):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.suptitle(system_name)\n",
    "    fig.set_figwidth(16)\n",
    "    fig.set_figheight(12)\n",
    "\n",
    "    df = pandas\\\n",
    "    .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "    .query(\"system_name == '{}'\".format(\"spring\"))\\\n",
    "    .groupby([\"method_name\", \"integrator_name\"])\\\n",
    "    .agg({\"inference_time\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    \n",
    "    df\\\n",
    "    .pivot(index=\"method_name\", columns=[\"integrator_name\"], values=\"mean_inference_time\")\\\n",
    "    .plot(ax=ax, kind=\"bar\", logy=True)\n",
    "        \n",
    "\n",
    "    def style_update(ax):\n",
    "        ax.grid()\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        ax.legend(loc=\"upper center\")\n",
    "        ax.set_ylabel(\"Relative Error (mean over trajectories, timesteps)\")\n",
    "\n",
    "    style_update(ax)\n",
    "    plt.show()\n",
    "plot_system_performance(\"spring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Trajectory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas\\\n",
    ".merge(aggregate_data, inferred_data, on=\"experiment_name\")\n",
    "df = pandas.merge(df, ground_truth_data, on=[\"experiment_name\", \"trajectory_number\", \"timestep_number\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = df.loc[(df[\"system_name\"] == \"wave\") &\n",
    "                (df[\"method_name\"] == \"srnn\") & \n",
    "                (df[\"network_depth\"] == 2) & \n",
    "                (df[\"network_hidden_dim\"] == 256) & \n",
    "                (df[\"num_train_trajectories\"] == 500)]\n",
    "run_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = run_df.loc[(run_df[\"trajectory_number\"] == 0)][[\"inferred_data\", \"ground_truth_data\"]]\n",
    "inferred_data_ = np.stack([entry[0] for entry in single_run.values])\n",
    "ground_truth_data_ = np.stack([entry[1] for entry in single_run.values])\n",
    "def plot_t(t):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(inferred_data_[t, ...], \"*\")\n",
    "    plt.plot(ground_truth_data_[t, ...], \":\")\n",
    "    plt.plot()\n",
    "\n",
    "widgets.interact(plot_t, t=widgets.IntSlider(value=0, min=0, max=999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRNN Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "for ax_, integrator_name in zip(itertools.chain(*ax), itertools.chain([\"euler\", \"leapfrog\"], [\"rk4\", \"scipy-RK45\"])):\n",
    "    df = pandas\\\n",
    "            .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "            .query(\"system_name == 'spring' and method_name == 'srnn' and timestep_number == 1000 and integrator_name == '{}'\".format(integrator_name))\\\n",
    "            .groupby([\"num_train_trajectories\", \"integrator_timestep_size\"])\\\n",
    "            .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "    df = df.pivot(index=\"integrator_timestep_size\", columns=[\"num_train_trajectories\"], values=\"mean_relerr_l2\")\n",
    "\n",
    "    for column in df.columns:\n",
    "        ax_.plot(df[column], label=column)\n",
    "\n",
    "    df = pandas\\\n",
    "            .merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "            .query(\"system_name == 'spring' and method_name == 'integrator-baseline' and timestep_number == 1000 and integrator_name == '{}'\".format(integrator_name))\\\n",
    "            .groupby([\"integrator_timestep_size\"])\\\n",
    "            .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "\n",
    "    ax_.plot(df[\"integrator_timestep_size\"], df[\"mean_relerr_l2\"], label=\"integrator-baseline\")\n",
    "    ax_.set_title(integrator_name)\n",
    "    ax_.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "delta = aggregate_data[\"integrator_timestep_size\"].unique()\n",
    "timestep = ((1000 * delta.min())/delta).astype(np.int)\n",
    "conversion = {dt : t for dt, t in zip(delta, timestep)}\n",
    "\n",
    "for ax_, integrator_name in zip(itertools.chain(*ax), itertools.chain([\"euler\", \"leapfrog\"], [\"rk4\", \"scipy-RK45\"])):\n",
    "    df = pandas.merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "    .query(\"system_name == 'spring' and method_name == 'srnn' and integrator_name == '{}'\".format(integrator_name))\n",
    "    timesteps = df[\"integrator_timestep_size\"].map(lambda x : conversion[x])\n",
    "    df = df.loc[df[\"timestep_number\"] == timesteps]\n",
    "    inference_time_per_timestep = pandas.DataFrame({\n",
    "        \"experiment_name\": aggregate_data[\"experiment_name\"], \n",
    "        \"inference_time_per_timestep\" : (aggregate_data[\"inference_time\"] / inferred_data[\"timestep_number\"].max())\n",
    "    })\n",
    "    df = pandas.merge(df, inference_time_per_timestep, on=\"experiment_name\")\n",
    "    df[\"cpu_time\"] = df.inference_time_per_timestep * df.timestep_number\n",
    "\n",
    "    df = df.groupby([\"num_train_trajectories\", \"cpu_time\"])\\\n",
    "    .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "    group = df.groupby(\"num_train_trajectories\")\n",
    "    group_keys = list(group.groups.keys())\n",
    "    for i, grp in enumerate(group.groups):\n",
    "        mini_df = group.get_group(grp)\n",
    "        ax_.plot(mini_df[\"cpu_time\"], mini_df[\"mean_relerr_l2\"], label=group_keys[i])\n",
    "\n",
    "    df = pandas.merge(aggregate_data, inferred_data, on=\"experiment_name\")\\\n",
    "    .query(\"system_name == 'spring' and method_name == 'integrator-baseline' and integrator_name == '{}'\".format(integrator_name))\n",
    "    timesteps = df[\"integrator_timestep_size\"].map(lambda x : conversion[x])\n",
    "    df = df.loc[df[\"timestep_number\"] == timesteps]\n",
    "    inference_time_per_timestep = pandas.DataFrame({\n",
    "        \"experiment_name\": aggregate_data[\"experiment_name\"], \n",
    "        \"inference_time_per_timestep\" : (aggregate_data[\"inference_time\"] / inferred_data[\"timestep_number\"].max())\n",
    "    })\n",
    "    df = pandas.merge(df, inference_time_per_timestep, on=\"experiment_name\")\n",
    "    df[\"cpu_time\"] = df.inference_time_per_timestep * df.timestep_number\n",
    "\n",
    "    df = df.groupby([\"cpu_time\"])\\\n",
    "    .agg({\"relerr_l2\" : \"mean\"}).add_prefix(\"mean_\").reset_index()\n",
    "    \n",
    "    ax_.plot(df[\"cpu_time\"], df[\"mean_relerr_l2\"], label=\"integrator-baseline\")\n",
    "#     ax_.set(ylim=(0, 0.4))\n",
    "    ax_.set_title(integrator_name)\n",
    "    ax_.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Validation Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {}\n",
    "dirname = os.path.join(data_dir, \"run/train/\")\n",
    "for root, folders, files in os.walk(dirname):\n",
    "    if \"train_stats.json\" in files:\n",
    "        with open(os.path.join(root, \"train_stats.json\"), \"r\") as file_:\n",
    "            data = json.load(file_)\n",
    "        train_loss = np.array([data[\"epoch_stats\"][i][\"train_total_loss\"] / data[\"epoch_stats\"][i][\"train_loss_denom\"] for i in range(400)])\n",
    "        val_loss = np.array([data[\"epoch_stats\"][i][\"val_total_loss\"] / data[\"epoch_stats\"][i][\"val_loss_denom\"] for i in range(400)])\n",
    "        losses[os.path.basename(root)[len(\"wave-architecture-test\")+1:]] = [train_loss, val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(key):\n",
    "    plt.semilogy(losses[key][0])\n",
    "    plt.semilogy(losses[key][1])\n",
    "\n",
    "key = widgets.Dropdown(\n",
    "    options=losses.keys(),\n",
    "    description='Key:',\n",
    "    disabled=False,\n",
    "    button_style='' # 'success', 'info', 'warning', 'danger' or ''\n",
    ")\n",
    "\n",
    "widgets.interact(plot_loss, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "i = 0\n",
    "plt.figure(figsize=(30, 20))\n",
    "for d in [2, 3, 4]:\n",
    "    for h in [200, 1024, 2048, 4096]:\n",
    "        i += 1\n",
    "        try:\n",
    "            ax = plt.subplot(3, 4, i, sharex=ax, sharey=ax)\n",
    "            key = f\"hnn-train-wave-n500-t2500-n0.0-d{d}-h{h}_00001\"\n",
    "            plot_loss(key)\n",
    "            plt.title(f\"{d}-{h}\")\n",
    "        except KeyError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "i = 0\n",
    "plt.figure(figsize=(30, 20))\n",
    "for d in [2, 3, 4]:\n",
    "    for h in [200, 1024, 2048, 4096]:\n",
    "        i += 1\n",
    "        try:\n",
    "            ax = plt.subplot(3, 4, i, sharex=ax, sharey=ax)\n",
    "            key = f\"srnn-train-wave-n500-t2500-n0.0-d{d}-h{h}-ieuler_00001\"\n",
    "            plot_loss(key)\n",
    "            plt.title(f\"{d}-{h}\")\n",
    "        except KeyError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
